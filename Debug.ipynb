{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e309d6f9-a352-4a26-803d-3adaab3d2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S2\n",
      "0.9066982912115655\n",
      "Processing S3\n",
      "0.6659446350826342\n",
      "Processing S4\n",
      "1.0\n",
      "Processing S5\n",
      "0.9842501175364363\n",
      "Processing S6\n",
      "0.991654744873629\n",
      "Processing S7\n",
      "0.9861626412087617\n",
      "Processing S8\n",
      "0.9854554124940392\n",
      "Processing S9\n",
      "1.0\n",
      "Processing S10\n",
      "1.0\n",
      "Processing S11\n",
      "1.0\n",
      "Processing S13\n",
      "1.0\n",
      "Processing S14\n",
      "1.0\n",
      "Processing S15\n",
      "0.9823717948717948\n",
      "Processing S16\n",
      "1.0\n",
      "Processing S17\n",
      "0.9011021500342652\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from collections import Counter\n",
    "from Model_Utils import Sequence_Model, Classify_Model, Embedding_Model, HeadProjection_Model, Model_Combine\n",
    "from Dataset_Utils import *\n",
    "from General_Utils import *\n",
    "from Loss_Utils import *\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# 14, 6, 17, 3, 2, 13, 9, 10, 15, 8, 7, 11, 4, 5, 16\n",
    "SUBJECT_ID_TEST = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "SUBJECT_ID_TEST = ['S'+str(x) for x in SUBJECT_ID_TEST]\n",
    "# SUBJECT_ID_TEST = 'S16'\n",
    "result_personal = {}\n",
    "\n",
    "# # 'GM1', 'EK1', 'NM1', 'RY1', 'KSG1', 'AD1', 'NM3', 'SJ1', 'BK1', 'RY2', 'GM2', 'MT1', 'NM2'\n",
    "# SUBJECT_ID_TEST = 'AD1' # SJ1\n",
    "\n",
    "USE_LARS = True\n",
    "OPTIM = 'Adam'\n",
    "LR = 0.003\n",
    "\n",
    "MARGIN = 1\n",
    "SEQ_DIM = 128\n",
    "INPUT_FT = 60\n",
    "EMBEDDING_HIDDEN = [256, 512]\n",
    "PROJECTION_OUT = None #128 # None or int\n",
    "CLASSIFY_HIDDEN = [-1] # [64] # list or None\n",
    "DROPOUT = 0.2\n",
    "\n",
    "MAX_EPOCH = 50\n",
    "LOOK_BEFORE = 3\n",
    "INTERNAL_SAMPLE = 200\n",
    "\n",
    "MODEL_NAME = 'Euclid_CLS_512_LARS_Adam'\n",
    "SAVE_MODEL_DIR = 'Output'\n",
    "NAME_DATASET = 'WESAD'\n",
    "\n",
    "##### READ DATASET #####\n",
    "if NAME_DATASET == 'WESAD':\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/WESAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_groups_1_60.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_ground_truth_1_60.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_stats_feats_1_60.npy')\n",
    "else:\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/AffectiveROAD_Data/Database'\n",
    "    NAME_DATASET = 'AffectiveROAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_groups_1.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_ground_truth_1.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_stats_feats_1.npy')\n",
    "    indices = np.where(data_gt >= 0)[0]\n",
    "    data_ft = data_ft[indices]\n",
    "    data_group = data_group[indices]\n",
    "    data_gt = data_gt[indices]\n",
    "\n",
    "# Create dataframe for dataset\n",
    "column_values = [f'f{x}' for x in range(data_ft.shape[1])]\n",
    "data_full = pd.DataFrame(data = data_ft,  \n",
    "                         columns = column_values)\n",
    "data_full['subject_id'] = data_group\n",
    "data_full['label'] = data_gt\n",
    "list_subject_id = np.unique(data_full['subject_id']).tolist()\n",
    "\n",
    "##### TRAIN / VAL / TEST #####\n",
    "for subject_id_test in SUBJECT_ID_TEST:\n",
    "    print(f'Processing {subject_id_test}')\n",
    "    data_test = data_full[data_full.subject_id == subject_id_test]\n",
    "    ft_names = data_test.columns.tolist()\n",
    "\n",
    "    # Scaler Data\n",
    "    X_test = data_test.iloc[:,:-2].to_numpy()\n",
    "    group_test = data_test.iloc[:,-2].to_numpy()\n",
    "    y_test = data_test.iloc[:,-1].to_numpy()\n",
    "\n",
    "    X_test = X_test.astype('float64')\n",
    "    y_test = y_test.astype('float64')\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    list_fold = {}\n",
    "    count = 0\n",
    "    for train_index, test_index in skf.split(X_test, y_test):\n",
    "        list_fold[count] = {}\n",
    "        list_fold[count]['train_idx'] = train_index\n",
    "        list_fold[count]['test_idx'] = test_index\n",
    "        count += 1\n",
    "    \n",
    "    sum_bacc = 0\n",
    "    for f in range(3):\n",
    "        train_index = list_fold[f]['train_idx']\n",
    "        test_index = list_fold[f]['test_idx']\n",
    "        X_train = X_test[train_index]\n",
    "        y_train = y_test[train_index]\n",
    "        X_test_t = X_test[test_index]\n",
    "        y_test_t = y_test[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test_t = scaler.transform(X_test_t)\n",
    "        clf = RandomForestClassifier(n_estimators = 1000, random_state = 0, \n",
    "                                     n_jobs = -1, max_features='sqrt', \n",
    "                                     oob_score=True, bootstrap=True, class_weight = 'balanced')\n",
    "        #clf = SVC(kernel='rbf', random_state=0, \n",
    "        #          class_weight='balanced', C=10)\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Prediction\n",
    "        Y_pred_test = clf.predict(X_test_t)\n",
    "        acc_test = accuracy_score(y_test_t, Y_pred_test)\n",
    "        f1_test = f1_score(y_test_t, Y_pred_test)\n",
    "        bacc_test = balanced_accuracy_score(y_test_t, Y_pred_test)\n",
    "        sum_bacc += bacc_test\n",
    "    sum_bacc /= 3\n",
    "    result_personal[subject_id_test] = sum_bacc\n",
    "    print(sum_bacc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a69d73-fcd9-41c1-b56c-a9ee79edc8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S2': 0.9066982912115655,\n",
       " 'S3': 0.6659446350826342,\n",
       " 'S4': 1.0,\n",
       " 'S5': 0.9842501175364363,\n",
       " 'S6': 0.991654744873629,\n",
       " 'S7': 0.9861626412087617,\n",
       " 'S8': 0.9854554124940392,\n",
       " 'S9': 1.0,\n",
       " 'S10': 1.0,\n",
       " 'S11': 1.0,\n",
       " 'S13': 1.0,\n",
       " 'S14': 1.0,\n",
       " 'S15': 0.9823717948717948,\n",
       " 'S16': 1.0,\n",
       " 'S17': 0.9011021500342652}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afb5649-683a-4aad-96e2-8d15baacad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S14\n",
      "2721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from collections import Counter\n",
    "from Model_Utils import Sequence_Model, Classify_Model, Embedding_Model, HeadProjection_Model, Model_Combine\n",
    "from Dataset_Utils import *\n",
    "from General_Utils import *\n",
    "from Loss_Utils import *\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# 14, 6, 17, 3, 2, 13, 9, 10, 15, 8, 7, 11, 4, 5, 16\n",
    "SUBJECT_ID_TEST = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "SUBJECT_ID_TEST = ['S'+str(x) for x in SUBJECT_ID_TEST]\n",
    "SUBJECT_ID_TEST = 'S14'\n",
    "subject_id_test = SUBJECT_ID_TEST\n",
    "result_personal = {}\n",
    "\n",
    "# # 'GM1', 'EK1', 'NM1', 'RY1', 'KSG1', 'AD1', 'NM3', 'SJ1', 'BK1', 'RY2', 'GM2', 'MT1', 'NM2'\n",
    "# SUBJECT_ID_TEST = 'AD1' # SJ1\n",
    "\n",
    "USE_LARS = True\n",
    "OPTIM = 'Adam'\n",
    "LR = 0.003\n",
    "\n",
    "EDA_FT = 35\n",
    "EMB_EDA_SIZE = [70, 35]\n",
    "HR_FT = 25\n",
    "EMB_HR_SIZE = [50, 25]\n",
    "CLS_SIZE = None # None or List\n",
    "\n",
    "MAX_EPOCH = 50\n",
    "USE_RES = False\n",
    "OPTIM = 'Adam'\n",
    "LR = 0.003\n",
    "DROPOUT = 0.4\n",
    "ACTIVATION = 'relu'\n",
    "MODEL_NAME = 'Adam_Encode_Balance_W60'\n",
    "SAVE_MODEL_DIR = 'Output_CLS_Val_X'\n",
    "SUBFOLDER = 'Encode_Balance_DO4'\n",
    "NAME_DATASET = 'WESAD'\n",
    "\n",
    "##### READ DATASET #####\n",
    "if NAME_DATASET == 'WESAD':\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/WESAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_groups_1_60.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_ground_truth_1_60.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_stats_feats_1_60.npy')\n",
    "else:\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/AffectiveROAD_Data/Database'\n",
    "    NAME_DATASET = 'AffectiveROAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_groups_1.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_ground_truth_1.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_stats_feats_1.npy')\n",
    "    indices = np.where(data_gt >= 0)[0]\n",
    "    data_ft = data_ft[indices]\n",
    "    data_group = data_group[indices]\n",
    "    data_gt = data_gt[indices]\n",
    "\n",
    "# Create dataframe for dataset\n",
    "column_values = [f'f{x}' for x in range(data_ft.shape[1])]\n",
    "data_full = pd.DataFrame(data = data_ft,  \n",
    "                         columns = column_values)\n",
    "data_full['subject_id'] = data_group\n",
    "data_full['label'] = data_gt\n",
    "list_subject_id = np.unique(data_full['subject_id']).tolist()\n",
    "ft_names = data_full.columns.tolist()\n",
    "##### TRAIN / VAL / TEST #####\n",
    "print(f'Processing {subject_id_test}')\n",
    "data_test = data_full[data_full.subject_id == subject_id_test]\n",
    "\n",
    "data_train_val = data_full[data_full.subject_id != subject_id_test]\n",
    "print(len(data_test))\n",
    "list_id = list(set(data_train_val.subject_id))\n",
    "list_id.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8488713a-0a5e-400f-9220-a414f8fa3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Embedding_Model(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.4, emb_size=[64], activation='relu'):\n",
    "        super(Embedding_Model, self).__init__()\n",
    "        self.do = dropout\n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        modules = [] \n",
    "        for idx, size in enumerate(self.emb_size):\n",
    "            if idx != len(self.emb_size) - 1: # Not the last layer\n",
    "                if idx == 0:\n",
    "                    modules.append(nn.Linear(self.input_size, self.emb_size[idx]))\n",
    "                else:\n",
    "                    modules.append(nn.Linear(self.emb_size[idx-1], self.emb_size[idx]))\n",
    "                modules.append(nn.BatchNorm1d(num_features=self.emb_size[idx]))\n",
    "                if activation == 'relu':\n",
    "                    modules.append(nn.ReLU())\n",
    "                else:\n",
    "                    modules.append(MemoryEfficientSwish())\n",
    "                modules.append(nn.Dropout(self.do))   \n",
    "            else:\n",
    "                # This is the last layer\n",
    "                if idx == 0:\n",
    "                    modules.append(nn.Linear(self.input_size, self.emb_size[idx]))\n",
    "                else:\n",
    "                    modules.append(nn.Linear(self.emb_size[idx-1], self.emb_size[idx]))\n",
    " \n",
    "        self.emb = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, feat):\n",
    "        x = self.emb(feat)\n",
    "        #x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Model_CLS(nn.Module):\n",
    "    def __init__(self, input_eda_size, input_hr_size, emb_eda_size=None, emb_hr_size=None, \n",
    "                 dropout=0.2, cls_size=None, activation='relu', use_res=False):\n",
    "        # cls_size, emb_eda_size, emb_hr_size is None or a list\n",
    "        \n",
    "        super(Model_CLS, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        if emb_eda_size[-1] != input_eda_size or emb_hr_size[-1] != input_hr_size:\n",
    "            self.use_res = False\n",
    "        else:\n",
    "            self.use_res = use_res\n",
    "            \n",
    "        self.input_eda_size = input_eda_size\n",
    "        if emb_eda_size is None:\n",
    "            self.emb_eda_size = [input_eda_size]\n",
    "        else:\n",
    "            self.emb_eda_size = emb_eda_size\n",
    "        self.eda_encode = Embedding_Model(input_size=self.input_eda_size, \n",
    "                                          dropout=self.dropout, \n",
    "                                          emb_size=self.emb_eda_size, activation=activation)\n",
    "        \n",
    "        self.input_hr_size = input_hr_size\n",
    "        if emb_hr_size is None:\n",
    "            self.emb_hr_size = [input_hr_size]\n",
    "        else:\n",
    "            self.emb_hr_size = emb_hr_size\n",
    "        self.hr_encode = Embedding_Model(input_size=self.input_hr_size, \n",
    "                                         dropout=self.dropout, \n",
    "                                         emb_size=self.emb_hr_size, activation=activation)\n",
    "        \n",
    "        self.input_cls_size = self.emb_eda_size[-1] + self.emb_hr_size[-1]\n",
    "        if cls_size is None:\n",
    "            self.cls_size = [1]\n",
    "        else:\n",
    "            self.cls_size = cls_size + [1]\n",
    "        self.cls = Embedding_Model(input_size=self.input_cls_size, \n",
    "                                   dropout=self.dropout, \n",
    "                                   emb_size=self.cls_size, activation=activation)\n",
    "        \n",
    "        self.eda_cls = Embedding_Model(input_size=self.emb_eda_size[-1], \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1], activation=activation)\n",
    "        self.hr_cls = Embedding_Model(input_size=self.emb_hr_size[-1], \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1], activation=activation)\n",
    "            \n",
    "    def forward(self, eda_ft, hr_ft):\n",
    "        eda_emb = self.eda_encode(eda_ft)\n",
    "        hr_emb = self.hr_encode(hr_ft)\n",
    "        \n",
    "        if self.use_res:\n",
    "            eda_emb = eda_emb + eda_ft\n",
    "            hr_emb = hr_emb + hr_ft\n",
    "            \n",
    "        eda_logit = self.eda_cls(eda_emb)\n",
    "        hr_logit = self.hr_cls(hr_emb)\n",
    "        \n",
    "        com_emb = torch.cat((eda_emb,hr_emb), dim=1)\n",
    "        #if self.use_res:\n",
    "        #    com_emb = com_emb + torch.cat((eda_ft, hr_ft), dim=1)\n",
    "        com_logit = self.cls(com_emb)\n",
    "        \n",
    "        return eda_logit, hr_logit, com_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a33c1b-5a62-4cc9-86c1-5a85bd0c849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        '''\n",
    "        df is the dataframe containing features + subject_id + label\n",
    "        numb_samples (int) total of pairs (samples) want to generated\n",
    "        '''\n",
    "        self.df = df.copy()\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        sample_1 = self.df.iloc[i,:-2].to_numpy(dtype=np.float64) # not include subject_id and label\n",
    "        label_1 = self.df['label'][i]\n",
    "        hr_ft = sample_1[0:25]\n",
    "        eda_ft = sample_1[25:]\n",
    "        return eda_ft, hr_ft, label_1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def generate_batch_embed(batch):\n",
    "    eda_fts, hr_fts,labels = zip(*batch)\n",
    "    eda_ft = torch.tensor([ft for ft in eda_fts]).squeeze(1).float()#.to(device)\n",
    "    hr_ft = torch.tensor([ft for ft in hr_fts]).squeeze(1).float()\n",
    "    labels = torch.tensor(labels).float()#.to(device)\n",
    "    return eda_ft, hr_ft, labels\n",
    "\n",
    "# Dataloader Class\n",
    "def make_EmbDataLoader(dataset, **args):\n",
    "    data = DataLoader(dataset, collate_fn=generate_batch_embed, **args)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0fc34f-524f-4222-992d-d12ea03ca7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_dict(model_dict, dataloader_dict):\n",
    "    list_validate_id = list(model_dict.keys())\n",
    "    all_pred_eda_dict = {}\n",
    "    all_pred_hr_dict = {}\n",
    "    all_pred_com_dict = {}\n",
    "    all_pred_cat_dict = {}\n",
    "    all_pred_eda_prob_dict = {}\n",
    "    all_pred_hr_prob_dict = {}\n",
    "    all_pred_com_prob_dict = {}\n",
    "    all_pred_cat_prob_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_id, subject_id_validate in enumerate(list_validate_id):\n",
    "            dataloader = dataloader_dict[subject_id_validate]\n",
    "            model = model_dict[subject_id_validate]\n",
    "            model.eval()\n",
    "            \n",
    "            all_pred_eda = []\n",
    "            all_pred_hr = []\n",
    "            all_pred_com = []\n",
    "            all_pred_cat = []\n",
    "            all_pred_eda_prob = []\n",
    "            all_pred_hr_prob = []\n",
    "            all_pred_com_prob = []\n",
    "            all_pred_cat_prob = []\n",
    "    \n",
    "            if idx_id == 0:\n",
    "                all_label = []\n",
    "                \n",
    "            for i, (eda_ft, hr_ft, labels) in enumerate(dataloader):\n",
    "                eda_ft = eda_ft.to(device)\n",
    "                hr_ft = hr_ft.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.unsqueeze(-1)\n",
    "\n",
    "                eda_logit, hr_logit, com_logit = model(eda_ft, hr_ft)\n",
    "                eda_cls = sigmoid_function(eda_logit)\n",
    "                hr_cls = sigmoid_function(hr_logit)\n",
    "                com_cls = sigmoid_function(com_logit)\n",
    "                cat_cls = (eda_cls + hr_cls + com_cls)/3\n",
    "            \n",
    "                preds_eda_round_list = eda_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_hr_round_list = hr_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_com_round_list = com_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_cat_round_list = cat_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "                \n",
    "                preds_eda_prob_list = eda_cls.squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_hr_prob_list = hr_cls.squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_com_prob_list = com_cls.squeeze().detach().cpu().numpy().tolist()\n",
    "                preds_cat_prob_list = cat_cls.squeeze().detach().cpu().numpy().tolist()\n",
    "                \n",
    "                labels = labels.round().squeeze().detach().cpu().numpy().tolist()\n",
    "                \n",
    "                all_pred_eda += preds_eda_round_list\n",
    "                all_pred_com += preds_com_round_list\n",
    "                all_pred_hr += preds_hr_round_list\n",
    "                all_pred_cat += preds_cat_round_list\n",
    "                all_pred_eda_prob += preds_eda_prob_list\n",
    "                all_pred_hr_prob += preds_hr_prob_list\n",
    "                all_pred_com_prob += preds_com_prob_list\n",
    "                all_pred_cat_prob += preds_cat_prob_list\n",
    "                \n",
    "                if idx_id == 0:\n",
    "                    all_label += labels\n",
    "                    \n",
    "            all_pred_eda_dict[subject_id_validate] = all_pred_eda\n",
    "            all_pred_hr_dict[subject_id_validate] = all_pred_hr\n",
    "            all_pred_com_dict[subject_id_validate] = all_pred_com\n",
    "            all_pred_cat_dict[subject_id_validate] = all_pred_cat\n",
    "            all_pred_eda_prob_dict[subject_id_validate] = all_pred_eda_prob\n",
    "            all_pred_hr_prob_dict[subject_id_validate] = all_pred_hr_prob\n",
    "            all_pred_com_prob_dict[subject_id_validate] = all_pred_com_prob\n",
    "            all_pred_cat_prob_dict[subject_id_validate] = all_pred_cat_prob\n",
    "    \n",
    "    for idx, subject_id_validate in enumerate(list_validate_id):\n",
    "        if idx == 0:\n",
    "            f_pred_eda = np.array([all_pred_eda_dict[subject_id_validate]])\n",
    "            f_pred_hr = np.array([all_pred_hr_dict[subject_id_validate]])\n",
    "            f_pred_com = np.array([all_pred_com_dict[subject_id_validate]])\n",
    "            f_pred_cat = np.array([all_pred_cat_dict[subject_id_validate]])\n",
    "            f_pred_eda_prob = np.array([all_pred_eda_prob_dict[subject_id_validate]])\n",
    "            f_pred_hr_prob = np.array([all_pred_hr_prob_dict[subject_id_validate]])\n",
    "            f_pred_com_prob = np.array([all_pred_com_prob_dict[subject_id_validate]])\n",
    "            f_pred_cat_prob = np.array([all_pred_cat_prob_dict[subject_id_validate]])\n",
    "        else:\n",
    "            f_pred_eda = np.concatenate((f_pred_eda, np.array([all_pred_eda_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_hr = np.concatenate((f_pred_hr, np.array([all_pred_hr_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_com = np.concatenate((f_pred_com, np.array([all_pred_com_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_cat = np.concatenate((f_pred_cat, np.array([all_pred_cat_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_eda_prob = np.concatenate((f_pred_eda_prob, np.array([all_pred_eda_prob_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_hr_prob = np.concatenate((f_pred_hr_prob, np.array([all_pred_hr_prob_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_com_prob = np.concatenate((f_pred_com_prob, np.array([all_pred_com_prob_dict[subject_id_validate]])), axis=0)\n",
    "            f_pred_cat_prob = np.concatenate((f_pred_cat_prob, np.array([all_pred_cat_prob_dict[subject_id_validate]])), axis=0)\n",
    "    \n",
    "    \n",
    "    f_pred_eda = np.mean(f_pred_eda, axis=0)\n",
    "    f_pred_hr = np.mean(f_pred_hr, axis=0)\n",
    "    f_pred_com = np.mean(f_pred_com, axis=0)\n",
    "    f_pred_cat = np.mean(f_pred_cat, axis=0)\n",
    "    f_pred_eda_prob = np.mean(f_pred_eda_prob, axis=0)\n",
    "    f_pred_hr_prob = np.mean(f_pred_hr_prob, axis=0)\n",
    "    f_pred_com_prob = np.mean(f_pred_com_prob, axis=0)\n",
    "    f_pred_cat_prob = np.mean(f_pred_cat_prob, axis=0)\n",
    "    \n",
    "    f_pred_eda = np.round(f_pred_eda)\n",
    "    f_pred_hr = np.round(f_pred_hr)\n",
    "    f_pred_com = np.round(f_pred_com)\n",
    "    f_pred_cat = np.round(f_pred_cat)\n",
    "    f_pred_eda_prob = np.round(f_pred_eda_prob)\n",
    "    f_pred_hr_prob = np.round(f_pred_hr_prob)\n",
    "    f_pred_com_prob = np.round(f_pred_com_prob)\n",
    "    f_pred_cat_prob = np.round(f_pred_cat_prob)\n",
    "    \n",
    "    bacc_eda = balanced_accuracy_score(all_label, f_pred_eda)\n",
    "    acc_eda = accuracy_score(all_label, f_pred_eda)\n",
    "    f1_eda = f1_score(all_label, f_pred_eda)    \n",
    "    \n",
    "    bacc_hr = balanced_accuracy_score(all_label, f_pred_hr)\n",
    "    acc_hr = accuracy_score(all_label, f_pred_hr)\n",
    "    f1_hr = f1_score(all_label, f_pred_hr)  \n",
    "    \n",
    "    bacc_com = balanced_accuracy_score(all_label, f_pred_com)\n",
    "    acc_com = accuracy_score(all_label, f_pred_com)\n",
    "    f1_com = f1_score(all_label, f_pred_com) \n",
    "    \n",
    "    bacc_cat = balanced_accuracy_score(all_label, f_pred_cat)\n",
    "    acc_cat = accuracy_score(all_label, f_pred_cat)\n",
    "    f1_cat = f1_score(all_label, f_pred_cat) \n",
    "    \n",
    "    bacc_eda_prob = balanced_accuracy_score(all_label, f_pred_eda_prob)\n",
    "    acc_eda_prob = accuracy_score(all_label, f_pred_eda_prob)\n",
    "    f1_eda_prob = f1_score(all_label, f_pred_eda_prob)    \n",
    "    \n",
    "    bacc_hr_prob = balanced_accuracy_score(all_label, f_pred_hr_prob)\n",
    "    acc_hr_prob = accuracy_score(all_label, f_pred_hr_prob)\n",
    "    f1_hr_prob = f1_score(all_label, f_pred_hr_prob)  \n",
    "    \n",
    "    bacc_com_prob = balanced_accuracy_score(all_label, f_pred_com_prob)\n",
    "    acc_com_prob = accuracy_score(all_label, f_pred_com_prob)\n",
    "    f1_com_prob = f1_score(all_label, f_pred_com_prob) \n",
    "    \n",
    "    bacc_cat_prob = balanced_accuracy_score(all_label, f_pred_cat_prob)\n",
    "    acc_cat_prob = accuracy_score(all_label, f_pred_cat_prob)\n",
    "    f1_cat_prob = f1_score(all_label, f_pred_cat_prob) \n",
    "    \n",
    "    metric_dict = {}\n",
    "    metric_dict['eda'] = {}\n",
    "    metric_dict['eda']['acc'] = acc_eda\n",
    "    metric_dict['eda']['bacc'] = bacc_eda\n",
    "    metric_dict['eda']['f1'] = f1_eda\n",
    "    metric_dict['hr'] = {}\n",
    "    metric_dict['hr']['acc'] = acc_hr\n",
    "    metric_dict['hr']['bacc'] = bacc_hr\n",
    "    metric_dict['hr']['f1'] = f1_hr\n",
    "    metric_dict['com'] = {}\n",
    "    metric_dict['com']['acc'] = acc_com\n",
    "    metric_dict['com']['bacc'] = bacc_com\n",
    "    metric_dict['com']['f1'] = f1_com\n",
    "    metric_dict['cat'] = {}\n",
    "    metric_dict['cat']['acc'] = acc_cat\n",
    "    metric_dict['cat']['bacc'] = bacc_cat\n",
    "    metric_dict['cat']['f1'] = f1_cat\n",
    "    metric_dict['eda_prob'] = {}\n",
    "    metric_dict['eda_prob']['acc'] = acc_eda_prob\n",
    "    metric_dict['eda_prob']['bacc'] = bacc_eda_prob\n",
    "    metric_dict['eda_prob']['f1'] = f1_eda_prob\n",
    "    metric_dict['hr_prob'] = {}\n",
    "    metric_dict['hr_prob']['acc'] = acc_hr_prob\n",
    "    metric_dict['hr_prob']['bacc'] = bacc_hr_prob\n",
    "    metric_dict['hr_prob']['f1'] = f1_hr_prob\n",
    "    metric_dict['com_prob'] = {}\n",
    "    metric_dict['com_prob']['acc'] = acc_com_prob\n",
    "    metric_dict['com_prob']['bacc'] = bacc_com_prob\n",
    "    metric_dict['com_prob']['f1'] = f1_com_prob\n",
    "    metric_dict['cat_prob'] = {}\n",
    "    metric_dict['cat_prob']['acc'] = acc_cat_prob\n",
    "    metric_dict['cat_prob']['bacc'] = bacc_cat_prob\n",
    "    metric_dict['cat_prob']['f1'] = f1_cat_prob\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8b10e9-81cf-45ab-8292-b6d7f196a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on Test set in final ...\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "print('Run on Test set in final ...')\n",
    "X_test = data_test.iloc[:,:-2].to_numpy()\n",
    "group_test = data_test.iloc[:,-2].to_numpy()\n",
    "y_test = data_test.iloc[:,-1].to_numpy()\n",
    "model_dict = {}\n",
    "dataloader_dict = {}\n",
    "for subject_id_validate in list_id:\n",
    "    # Scaler Data\n",
    "    scaler = joblib.load(f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/{SUBFOLDER}/StandardScaler_{subject_id_test}_{subject_id_validate}.joblib')\n",
    "    X_test_scaler = scaler.transform(X_test)\n",
    "    # Create Dataframe\n",
    "    df_test= pd.DataFrame(data = X_test_scaler, columns = ft_names[:-2])\n",
    "    df_test['subject_id'] = group_test\n",
    "    df_test['label'] = y_test\n",
    "    # Create Dataset and Dataloader\n",
    "    test_dataset = EmbDataset(df_test)\n",
    "    test_dataloader = make_EmbDataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "    dataloader_dict[subject_id_validate] = test_dataloader\n",
    "    # Load Model\n",
    "    Model = Model_CLS(input_eda_size=EDA_FT, input_hr_size=HR_FT, \n",
    "                      emb_eda_size=EMB_EDA_SIZE, emb_hr_size=EMB_HR_SIZE, \n",
    "                      dropout=DROPOUT, cls_size=CLS_SIZE, activation=ACTIVATION, use_res=USE_RES)\n",
    "    Model = Model.to(device)\n",
    "\n",
    "    modelCheckpoint = torch.load(f\"{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/{SUBFOLDER}/{MODEL_NAME}_{subject_id_test}_{subject_id_validate}.pth.tar\")\n",
    "    Model.load_state_dict(modelCheckpoint['model_state_dict'])\n",
    "    model_dict[subject_id_validate] = Model\n",
    "    Model.eval()\n",
    "    # Predict\n",
    "    #test_metric_dict = validate_epoch(Model, test_dataloader)\n",
    "    #test_metric_info = metric_to_info(test_metric_dict)\n",
    "    #test_info = f'[CLASSIFY TEST {subject_id_test} - VALIDATE {subject_id_validate}]\\n'\n",
    "    #test_info += test_metric_info\n",
    "    #print(test_info)\n",
    "    #logging(test_info + '\\n', f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Log/{SUBFOLDER}/Test_{MODEL_NAME}_{subject_id_test}.txt', True)\n",
    "\n",
    "validate_test_metric_dict = test_model_dict(model_dict, dataloader_dict)\n",
    "#test_metric_info = metric_to_info(validate_test_metric_dict)\n",
    "#test_info = f'[FINAL CLASSIFY TEST {subject_id_test}]\\n'\n",
    "#test_info += test_metric_info\n",
    "#print(test_info)\n",
    "#logging(test_info + '\\n', f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Log/{SUBFOLDER}/Test_{MODEL_NAME}_{subject_id_test}.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f169e274-fd4c-4048-b118-b00ccb344f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eda': {'acc': 0.7894156560088202,\n",
       "  'bacc': 0.5341463414634147,\n",
       "  'f1': 0.1278538812785388},\n",
       " 'hr': {'acc': 0.8397647923557515,\n",
       "  'bacc': 0.7951821740439626,\n",
       "  'f1': 0.6681887366818874},\n",
       " 'com': {'acc': 0.8213891951488423,\n",
       "  'bacc': 0.6048780487804878,\n",
       "  'f1': 0.34677419354838707},\n",
       " 'cat': {'acc': 0.8213891951488423,\n",
       "  'bacc': 0.6048780487804878,\n",
       "  'f1': 0.34677419354838707},\n",
       " 'eda_prob': {'acc': 0.788680632120544,\n",
       "  'bacc': 0.532520325203252,\n",
       "  'f1': 0.1221374045801527},\n",
       " 'hr_prob': {'acc': 0.8401323042998897,\n",
       "  'bacc': 0.7971463646260395,\n",
       "  'f1': 0.670204700530705},\n",
       " 'com_prob': {'acc': 0.8195516354281515,\n",
       "  'bacc': 0.6008130081300813,\n",
       "  'f1': 0.33558863328822736},\n",
       " 'cat_prob': {'acc': 0.8195516354281515,\n",
       "  'bacc': 0.6008130081300813,\n",
       "  'f1': 0.33558863328822736}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_test_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8017d-a42a-4cd5-bdd3-3d8201391180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
