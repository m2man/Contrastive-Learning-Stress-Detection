{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd61322-c7ed-425c-a21e-88113e123b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda:0')\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "import joblib\n",
    "\n",
    "sigmoid_function = nn.Sigmoid()\n",
    "\n",
    "EDA_FT = 35\n",
    "EMB_EDA_SIZE = [35]\n",
    "HR_FT = 25\n",
    "EMB_HR_SIZE = [25]\n",
    "CLS_SIZE = [64] # None or List\n",
    "\n",
    "MAX_EPOCH = 50\n",
    "OPTIM = 'ADAM'\n",
    "LR = 0.003\n",
    "DROPOUT = 0.4\n",
    "\n",
    "MODEL_NAME = 'CLS_X_Adam'\n",
    "SAVE_MODEL_DIR = 'Output_CLS'\n",
    "NAME_DATASET = 'WESAD'\n",
    "SUBJECT_ID_TEST = 'S9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1211231-43c1-49d5-a8bc-3dd4a25aac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(s, path, print_=False):\n",
    "    if print_:\n",
    "        print(s)\n",
    "    if path:\n",
    "        with open(path, 'a+') as f:\n",
    "            f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fbc1ad-70ee-4a17-b932-711d1d76bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Embedding_Model(nn.Module):\n",
    "    def __init__(self, input_size, dropout=0.4, emb_size=[64]):\n",
    "        super(Embedding_Model, self).__init__()\n",
    "        self.do = dropout\n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        modules = [] \n",
    "        for idx, size in enumerate(self.emb_size):\n",
    "            if idx != len(self.emb_size) - 1: # Not the last layer\n",
    "                if idx == 0:\n",
    "                    modules.append(nn.Linear(self.input_size, self.emb_size[idx]))\n",
    "                else:\n",
    "                    modules.append(nn.Linear(self.emb_size[idx-1], self.emb_size[idx]))\n",
    "                modules.append(nn.BatchNorm1d(num_features=self.emb_size[idx]))\n",
    "                modules.append(nn.ReLU())\n",
    "                modules.append(nn.Dropout(self.do))   \n",
    "            else:\n",
    "                # This is the last layer\n",
    "                if idx == 0:\n",
    "                    modules.append(nn.Linear(self.input_size, self.emb_size[idx]))\n",
    "                else:\n",
    "                    modules.append(nn.Linear(self.emb_size[idx-1], self.emb_size[idx]))\n",
    " \n",
    "        self.emb = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, feat):\n",
    "        x = self.emb(feat)\n",
    "        #x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Model_CLS(nn.Module):\n",
    "    def __init__(self, input_eda_size, input_hr_size, emb_eda_size=None, emb_hr_size=None, dropout=0.2, cls_size=None):\n",
    "        # cls_size, emb_eda_size, emb_hr_size is None or a list\n",
    "        \n",
    "        super(Model_CLS, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.input_eda_size = input_eda_size\n",
    "        if emb_eda_size is None:\n",
    "            self.emb_eda_size = [input_eda_size]\n",
    "        else:\n",
    "            self.emb_eda_size = emb_eda_size\n",
    "        self.eda_encode = Embedding_Model(input_size=self.input_eda_size, \n",
    "                                          dropout=self.dropout, \n",
    "                                          emb_size=self.emb_eda_size)\n",
    "        \n",
    "        self.input_hr_size = input_hr_size\n",
    "        if emb_hr_size is None:\n",
    "            self.emb_hr_size = [input_hr_size]\n",
    "        else:\n",
    "            self.emb_hr_size = emb_hr_size\n",
    "        self.hr_encode = Embedding_Model(input_size=self.input_hr_size, \n",
    "                                         dropout=self.dropout, \n",
    "                                         emb_size=self.emb_hr_size)\n",
    "        \n",
    "        self.input_cls_size = self.emb_eda_size[-1] + self.emb_hr_size[-1]\n",
    "        if cls_size is None:\n",
    "            self.cls_size = [1]\n",
    "        else:\n",
    "            self.cls_size = cls_size + [1]\n",
    "        self.cls = Embedding_Model(input_size=self.input_cls_size, \n",
    "                                   dropout=self.dropout, \n",
    "                                   emb_size=self.cls_size)\n",
    "        \n",
    "        self.eda_cls = Embedding_Model(input_size=self.emb_eda_size[-1], \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1])\n",
    "        self.hr_cls = Embedding_Model(input_size=self.emb_hr_size[-1], \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1])\n",
    "            \n",
    "    def forward(self, eda_ft, hr_ft):\n",
    "        eda_emb = self.eda_encode(eda_ft)\n",
    "        hr_emb = self.hr_encode(hr_ft)\n",
    "        \n",
    "        eda_logit = self.eda_cls(eda_emb)\n",
    "        hr_logit = self.hr_cls(hr_emb)\n",
    "        \n",
    "        com_emb = torch.cat((eda_emb,hr_emb), dim=1)\n",
    "        com_logit = self.cls(com_emb)\n",
    "        \n",
    "        return eda_logit, hr_logit, com_logit\n",
    "\n",
    "class Model_CLS_X(nn.Module):\n",
    "    def __init__(self, input_eda_size, input_hr_size, emb_eda_size=None, emb_hr_size=None, dropout=0.2, cls_size=None):\n",
    "        # cls_size, emb_eda_size, emb_hr_size is None or a list\n",
    "        \n",
    "        super(Model_CLS_X, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.input_eda_size = input_eda_size\n",
    "        if emb_eda_size is None:\n",
    "            self.emb_eda_size = [input_eda_size]\n",
    "        else:\n",
    "            self.emb_eda_size = emb_eda_size\n",
    "        self.eda_encode = Embedding_Model(input_size=self.input_eda_size, \n",
    "                                          dropout=self.dropout, \n",
    "                                          emb_size=self.emb_eda_size)\n",
    "        \n",
    "        self.input_hr_size = input_hr_size\n",
    "        if emb_hr_size is None:\n",
    "            self.emb_hr_size = [input_hr_size]\n",
    "        else:\n",
    "            self.emb_hr_size = emb_hr_size\n",
    "        self.hr_encode = Embedding_Model(input_size=self.input_hr_size, \n",
    "                                         dropout=self.dropout, \n",
    "                                         emb_size=self.emb_hr_size)\n",
    "        \n",
    "        self.input_cls_size = self.emb_eda_size[-1] + self.emb_hr_size[-1] + input_hr_size + input_eda_size\n",
    "        if cls_size is None:\n",
    "            self.cls_size = [1]\n",
    "        else:\n",
    "            self.cls_size = cls_size + [1]\n",
    "        self.cls = Embedding_Model(input_size=self.input_cls_size, \n",
    "                                   dropout=self.dropout, \n",
    "                                   emb_size=self.cls_size)\n",
    "        \n",
    "        self.eda_cls = Embedding_Model(input_size=self.emb_eda_size[-1]+input_hr_size, \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1])\n",
    "        self.hr_cls = Embedding_Model(input_size=self.emb_hr_size[-1]+input_eda_size, \n",
    "                                       dropout=self.dropout, \n",
    "                                       emb_size=[1])\n",
    "            \n",
    "    def forward(self, eda_ft, hr_ft):\n",
    "        eda_emb = self.eda_encode(eda_ft)\n",
    "        hr_emb = self.hr_encode(hr_ft)\n",
    "        \n",
    "        eda_emb_cat = torch.cat((eda_emb, hr_ft), dim=1)\n",
    "        hr_emb_cat = torch.cat((hr_emb, eda_ft), dim=1)\n",
    "        \n",
    "        eda_logit = self.eda_cls(eda_emb_cat)\n",
    "        hr_logit = self.hr_cls(hr_emb_cat)\n",
    "        \n",
    "        com_emb = torch.cat((eda_emb, hr_emb, eda_ft, hr_ft), dim=1)\n",
    "        com_logit = self.cls(com_emb)\n",
    "        \n",
    "        return eda_logit, hr_logit, com_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6526a637-1b55-46e0-a52d-a19d052208bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revoting(subject_id_test, dataloader):\n",
    "    Model = Model_CLS_X(input_eda_size=EDA_FT, input_hr_size=HR_FT, \n",
    "                  emb_eda_size=EMB_EDA_SIZE, emb_hr_size=EMB_HR_SIZE, \n",
    "                  dropout=DROPOUT, cls_size=CLS_SIZE)\n",
    "    Model = Model.to(device)\n",
    "    modelCheckpoint = torch.load(f\"{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/{MODEL_NAME}_{subject_id_test}.pth.tar\")\n",
    "    Model.load_state_dict(modelCheckpoint['model_state_dict'])\n",
    "    Model.eval()\n",
    "    all_pred_eda = []\n",
    "    all_pred_hr = []\n",
    "    all_pred_com = []\n",
    "    all_pred_voting = []\n",
    "    all_label = []\n",
    "    with torch.no_grad():\n",
    "        for i, (eda_ft, hr_ft, labels) in enumerate(dataloader):\n",
    "            eda_ft = eda_ft.to(device)\n",
    "            hr_ft = hr_ft.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.unsqueeze(-1)\n",
    "\n",
    "            eda_logit, hr_logit, com_logit = Model(eda_ft, hr_ft)\n",
    "\n",
    "            eda_cls = sigmoid_function(eda_logit)\n",
    "            hr_cls = sigmoid_function(hr_logit)\n",
    "            com_cls = sigmoid_function(com_logit)\n",
    "            voting_cls = (eda_cls + hr_cls + hr_cls)/3\n",
    "            \n",
    "            preds_eda = eda_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_hr = hr_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_com = com_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_voting = voting_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            labels = labels.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            all_pred_eda += preds_eda\n",
    "            all_pred_com += preds_com\n",
    "            all_pred_hr += preds_hr\n",
    "            all_pred_voting += preds_voting\n",
    "            all_label += labels\n",
    "        \n",
    "        bacc_eda = balanced_accuracy_score(all_label, all_pred_eda)\n",
    "        acc_eda = accuracy_score(all_label, all_pred_eda)\n",
    "        f1_eda = f1_score(all_label, all_pred_eda)    \n",
    "\n",
    "        bacc_hr = balanced_accuracy_score(all_label, all_pred_hr)\n",
    "        acc_hr = accuracy_score(all_label, all_pred_hr)\n",
    "        f1_hr = f1_score(all_label, all_pred_hr)  \n",
    "\n",
    "        bacc_com = balanced_accuracy_score(all_label, all_pred_com)\n",
    "        acc_com = accuracy_score(all_label, all_pred_com)\n",
    "        f1_com = f1_score(all_label, all_pred_com)  \n",
    "        \n",
    "        bacc_vot = balanced_accuracy_score(all_label, all_pred_voting)\n",
    "        acc_vot = accuracy_score(all_label, all_pred_voting)\n",
    "        f1_vot = f1_score(all_label, all_pred_voting)  \n",
    "\n",
    "        metric_dict = {}\n",
    "        metric_dict['eda'] = {}\n",
    "        metric_dict['eda']['acc'] = acc_eda\n",
    "        metric_dict['eda']['bacc'] = bacc_eda\n",
    "        metric_dict['eda']['f1'] = f1_eda\n",
    "        metric_dict['hr'] = {}\n",
    "        metric_dict['hr']['acc'] = acc_hr\n",
    "        metric_dict['hr']['bacc'] = bacc_hr\n",
    "        metric_dict['hr']['f1'] = f1_hr\n",
    "        metric_dict['com'] = {}\n",
    "        metric_dict['com']['acc'] = acc_com\n",
    "        metric_dict['com']['bacc'] = bacc_com\n",
    "        metric_dict['com']['f1'] = f1_com\n",
    "        metric_dict['vot'] = {}\n",
    "        metric_dict['vot']['acc'] = acc_vot\n",
    "        metric_dict['vot']['bacc'] = bacc_vot\n",
    "        metric_dict['vot']['f1'] = f1_vot\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dac0b04-d24d-45d0-b2b1-32d9e977e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        '''\n",
    "        df is the dataframe containing features + subject_id + label\n",
    "        numb_samples (int) total of pairs (samples) want to generated\n",
    "        '''\n",
    "        self.df = df.copy()\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        sample_1 = self.df.iloc[i,:-2].to_numpy(dtype=np.float64) # not include subject_id and label\n",
    "        label_1 = self.df['label'][i]\n",
    "        hr_ft = sample_1[0:25]\n",
    "        eda_ft = sample_1[25:]\n",
    "        return eda_ft, hr_ft, label_1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def generate_batch_embed(batch):\n",
    "    eda_fts, hr_fts,labels = zip(*batch)\n",
    "    eda_ft = torch.tensor([ft for ft in eda_fts]).squeeze(1).float()#.to(device)\n",
    "    hr_ft = torch.tensor([ft for ft in hr_fts]).squeeze(1).float()\n",
    "    labels = torch.tensor(labels).float()#.to(device)\n",
    "    return eda_ft, hr_ft, labels\n",
    "\n",
    "# Dataloader Class\n",
    "def make_EmbDataLoader(dataset, **args):\n",
    "    data = DataLoader(dataset, collate_fn=generate_batch_embed, **args)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b582c7-18c0-4313-a940-bc352337ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, loss_func):\n",
    "    all_pred_eda = []\n",
    "    all_pred_hr = []\n",
    "    all_pred_com = []\n",
    "    all_label = []\n",
    "    eda_loss = []\n",
    "    hr_loss = []\n",
    "    com_loss = []\n",
    "    total_loss = []\n",
    "    dis_info = ''\n",
    "    model.train()\n",
    "        \n",
    "    for i, (eda_ft, hr_ft, labels) in enumerate(dataloader):\n",
    "        eda_ft = eda_ft.to(device)\n",
    "        hr_ft = hr_ft.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.unsqueeze(-1)\n",
    "        \n",
    "        eda_logit, hr_logit, com_logit = model(eda_ft, hr_ft)\n",
    "        \n",
    "        loss_eda = loss_func(eda_logit, labels)\n",
    "        loss_hr = loss_func(hr_logit, labels)\n",
    "        loss_com = loss_func(com_logit, labels)\n",
    "        loss_total = loss_eda + loss_hr + loss_com\n",
    "        \n",
    "        # Update Grad\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            eda_cls = sigmoid_function(eda_logit)\n",
    "            hr_cls = sigmoid_function(hr_logit)\n",
    "            com_cls = sigmoid_function(com_logit)\n",
    "       \n",
    "            total_loss.append(loss_total.item())\n",
    "            eda_loss.append(loss_eda.item())\n",
    "            hr_loss.append(loss_hr.item())\n",
    "            com_loss.append(loss_com.item())\n",
    "            \n",
    "            preds_eda = eda_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_hr = hr_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_com = com_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            labels = labels.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            all_pred_eda += preds_eda\n",
    "            all_pred_com += preds_com\n",
    "            all_pred_hr += preds_hr\n",
    "            all_label += labels\n",
    "\n",
    "        str_info = f'[Iter {i}/{len(dataloader)}] Total: {round(np.mean(total_loss), 4)}\\n'\n",
    "        str_info += f'EDA Loss: {round(np.mean(eda_loss), 4)}\\n'\n",
    "        str_info += f'HR Loss: {round(np.mean(hr_loss), 4)}\\n'\n",
    "        str_info += f'COM Loss: {round(np.mean(com_loss), 4)}'\n",
    "        if i % 100 == 0 or i == len(dataloader)-1:\n",
    "            print(str_info)\n",
    "            dis_info += str_info +'\\n'\n",
    "\n",
    "    dis_info += f\"Class Samples Distribution: {len(all_label) - np.sum(all_label)} / {np.sum(all_label)}\\n\"\n",
    "    \n",
    "    bacc_eda = balanced_accuracy_score(all_label, all_pred_eda)\n",
    "    acc_eda = accuracy_score(all_label, all_pred_eda)\n",
    "    f1_eda = f1_score(all_label, all_pred_eda)    \n",
    "    \n",
    "    bacc_hr = balanced_accuracy_score(all_label, all_pred_hr)\n",
    "    acc_hr = accuracy_score(all_label, all_pred_hr)\n",
    "    f1_hr = f1_score(all_label, all_pred_hr)  \n",
    "    \n",
    "    bacc_com = balanced_accuracy_score(all_label, all_pred_com)\n",
    "    acc_com = accuracy_score(all_label, all_pred_com)\n",
    "    f1_com = f1_score(all_label, all_pred_com)  \n",
    "    \n",
    "    loss_dict = {}\n",
    "    loss_dict['eda'] = np.mean(eda_loss)\n",
    "    loss_dict['hr'] = np.mean(hr_loss)\n",
    "    loss_dict['com'] = np.mean(com_loss)\n",
    "    loss_dict['total'] = np.mean(total_loss)\n",
    "    \n",
    "    metric_dict = {}\n",
    "    metric_dict['eda'] = {}\n",
    "    metric_dict['eda']['acc'] = acc_eda\n",
    "    metric_dict['eda']['bacc'] = bacc_eda\n",
    "    metric_dict['eda']['f1'] = f1_eda\n",
    "    metric_dict['hr'] = {}\n",
    "    metric_dict['hr']['acc'] = acc_hr\n",
    "    metric_dict['hr']['bacc'] = bacc_hr\n",
    "    metric_dict['hr']['f1'] = f1_hr\n",
    "    metric_dict['com'] = {}\n",
    "    metric_dict['com']['acc'] = acc_com\n",
    "    metric_dict['com']['bacc'] = bacc_com\n",
    "    metric_dict['com']['f1'] = f1_com\n",
    "    \n",
    "    return dis_info, loss_dict, metric_dict\n",
    "\n",
    "def validate_epoch(model, dataloader):\n",
    "    all_pred_eda = []\n",
    "    all_pred_hr = []\n",
    "    all_pred_com = []\n",
    "    all_label = []\n",
    "    eda_loss = []\n",
    "    hr_loss = []\n",
    "    com_loss = []\n",
    "    total_loss = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (eda_ft, hr_ft, labels) in enumerate(dataloader):\n",
    "            eda_ft = eda_ft.to(device)\n",
    "            hr_ft = hr_ft.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.unsqueeze(-1)\n",
    "\n",
    "            eda_logit, hr_logit, com_logit = model(eda_ft, hr_ft)\n",
    "\n",
    "            eda_cls = sigmoid_function(eda_logit)\n",
    "            hr_cls = sigmoid_function(hr_logit)\n",
    "            com_cls = sigmoid_function(com_logit)\n",
    "            \n",
    "            preds_eda = eda_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_hr = hr_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            preds_com = com_cls.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            labels = labels.round().squeeze().detach().cpu().numpy().tolist()\n",
    "            all_pred_eda += preds_eda\n",
    "            all_pred_com += preds_com\n",
    "            all_pred_hr += preds_hr\n",
    "            all_label += labels\n",
    "    \n",
    "    bacc_eda = balanced_accuracy_score(all_label, all_pred_eda)\n",
    "    acc_eda = accuracy_score(all_label, all_pred_eda)\n",
    "    f1_eda = f1_score(all_label, all_pred_eda)    \n",
    "    \n",
    "    bacc_hr = balanced_accuracy_score(all_label, all_pred_hr)\n",
    "    acc_hr = accuracy_score(all_label, all_pred_hr)\n",
    "    f1_hr = f1_score(all_label, all_pred_hr)  \n",
    "    \n",
    "    bacc_com = balanced_accuracy_score(all_label, all_pred_com)\n",
    "    acc_com = accuracy_score(all_label, all_pred_com)\n",
    "    f1_com = f1_score(all_label, all_pred_com)  \n",
    "    \n",
    "    metric_dict = {}\n",
    "    metric_dict['eda'] = {}\n",
    "    metric_dict['eda']['acc'] = acc_eda\n",
    "    metric_dict['eda']['bacc'] = bacc_eda\n",
    "    metric_dict['eda']['f1'] = f1_eda\n",
    "    metric_dict['hr'] = {}\n",
    "    metric_dict['hr']['acc'] = acc_hr\n",
    "    metric_dict['hr']['bacc'] = bacc_hr\n",
    "    metric_dict['hr']['f1'] = f1_hr\n",
    "    metric_dict['com'] = {}\n",
    "    metric_dict['com']['acc'] = acc_com\n",
    "    metric_dict['com']['bacc'] = bacc_com\n",
    "    metric_dict['com']['f1'] = f1_com\n",
    "    \n",
    "    return metric_dict\n",
    "\n",
    "def metric_to_info(metric_dict):\n",
    "    info = '~~~ EDA RESULT ~~~\\n'\n",
    "    info += f\"Acc: {round(np.mean(metric_dict['eda']['acc']), 4)}\"\n",
    "    info += f\" -- BAcc: {round(np.mean(metric_dict['eda']['bacc']), 4)}\"\n",
    "    info += f\" -- F1: {round(np.mean(metric_dict['eda']['f1']), 4)}\\n\"\n",
    "    info += '~~~ HR RESULT ~~~\\n'\n",
    "    info += f\"Acc: {round(np.mean(metric_dict['hr']['acc']), 4)}\"\n",
    "    info += f\" -- BAcc: {round(np.mean(metric_dict['hr']['bacc']), 4)}\"\n",
    "    info += f\" -- F1: {round(np.mean(metric_dict['hr']['f1']), 4)}\\n\"\n",
    "    info += '~~~ COM RESULT~~~\\n'\n",
    "    info += f\"Acc: {round(np.mean(metric_dict['com']['acc']), 4)}\"\n",
    "    info += f\" -- BAcc: {round(np.mean(metric_dict['com']['bacc']), 4)}\"\n",
    "    info += f\" -- F1: {round(np.mean(metric_dict['com']['f1']), 4)}\\n\"\n",
    "    return info\n",
    "\n",
    "def loss_to_info(loss_dict):\n",
    "    info = f\"TOTAL Loss: {round(np.mean(loss_dict['total']), 4)}\"\n",
    "    info += f\" -- EDA Loss: {round(np.mean(loss_dict['eda']), 4)}\"\n",
    "    info += f\" -- HR Loss: {round(np.mean(loss_dict['hr']), 4)}\"\n",
    "    info += f\" -- COM Loss: {round(np.mean(loss_dict['com']), 4)}\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5236f223-6af4-490b-b8e5-7e69934cd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### READ DATASET #####\n",
    "if NAME_DATASET == 'WESAD':\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/WESAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_groups_1_60.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_ground_truth_1_60.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_WRIST_stats_feats_1_60.npy')\n",
    "else:\n",
    "    DATA_DIR = '/home/nvtu/PhD_Work/StressDetection/DATA/MyDataset/AffectiveROAD_Data/Database'\n",
    "    NAME_DATASET = 'AffectiveROAD'\n",
    "    data_group = np.load(f'{DATA_DIR}/{NAME_DATASET}_groups_1.npy')\n",
    "    data_gt = np.load(f'{DATA_DIR}/{NAME_DATASET}_ground_truth_1.npy')\n",
    "    data_ft = np.load(f'{DATA_DIR}/{NAME_DATASET}_stats_feats_1.npy')\n",
    "    indices = np.where(data_gt >= 0)[0]\n",
    "    data_ft = data_ft[indices]\n",
    "    data_group = data_group[indices]\n",
    "    data_gt = data_gt[indices]\n",
    "\n",
    "# Create dataframe for dataset\n",
    "column_values = [f'f{x}' for x in range(data_ft.shape[1])]\n",
    "data_full = pd.DataFrame(data = data_ft,  \n",
    "                         columns = column_values)\n",
    "data_full['subject_id'] = data_group\n",
    "data_full['label'] = data_gt\n",
    "list_subject_id = np.unique(data_full['subject_id']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75ef365-e764-4265-82f4-8c8f38220fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for S9 and validate on S2\n"
     ]
    }
   ],
   "source": [
    "subject_id_test = SUBJECT_ID_TEST\n",
    "data_train_val = data_full[data_full.subject_id != subject_id_test]\n",
    "data_test = data_full[data_full.subject_id == subject_id_test]\n",
    "list_id = list(set(data_train_val.subject_id))\n",
    "list_id.sort()\n",
    "subject_id_validate = random.Random(1509+int(subject_id_test[1:])+88).choices(list_id,k=1)[0]\n",
    "#subject_id_validate = 'S8'\n",
    "data_train = data_train_val[data_train_val.subject_id != subject_id_validate]\n",
    "data_validate = data_train_val[data_train_val.subject_id == subject_id_validate]\n",
    "ft_names = data_train.columns.tolist()\n",
    "\n",
    "print(f\"Training Model for {subject_id_test} and validate on {subject_id_validate}\")\n",
    "\n",
    "#temp = Counter(data_train.iloc[:,-1].tolist())\n",
    "#print(temp)\n",
    "\n",
    "# Scaler Data\n",
    "X_train = data_train.iloc[:,:-2].to_numpy()\n",
    "group_train = data_train.iloc[:,-2].to_numpy()\n",
    "y_train = data_train.iloc[:,-1].to_numpy()\n",
    "X_test = data_test.iloc[:,:-2].to_numpy()\n",
    "group_test = data_test.iloc[:,-2].to_numpy()\n",
    "y_test = data_test.iloc[:,-1].to_numpy()\n",
    "X_validate = data_validate.iloc[:,:-2].to_numpy()\n",
    "group_validate = data_validate.iloc[:,-2].to_numpy()\n",
    "y_validate = data_validate.iloc[:,-1].to_numpy()\n",
    "\n",
    "X_train = X_train.astype('float64')\n",
    "X_validate = X_validate.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "y_train = y_train.astype('float64')\n",
    "y_validate = y_validate.astype('float64')\n",
    "y_test = y_test.astype('float64')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)\n",
    "#joblib.dump(scaler, f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/StandardScaler_{subject_id_test}.joblib')\n",
    "\n",
    "# Create Dataframe\n",
    "df_train = pd.DataFrame(data = X_train, columns = ft_names[:-2])\n",
    "df_train['subject_id'] = group_train\n",
    "df_train['label'] = y_train\n",
    "\n",
    "df_validate = pd.DataFrame(data = X_validate, columns = ft_names[:-2])\n",
    "df_validate['subject_id'] = group_validate\n",
    "df_validate['label'] = y_validate\n",
    "\n",
    "df_test= pd.DataFrame(data = X_test, columns = ft_names[:-2])\n",
    "df_test['subject_id'] = group_test\n",
    "df_test['label'] = y_test\n",
    "\n",
    "train_dataset = EmbDataset(df_train)\n",
    "validate_dataset = EmbDataset(df_validate)\n",
    "test_dataset = EmbDataset(df_test)\n",
    "\n",
    "train_dataloader = make_EmbDataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "validate_dataloader = make_EmbDataLoader(validate_dataset, batch_size=2048, shuffle=False)\n",
    "test_dataloader = make_EmbDataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "# cls_func = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Model = Model_CLS(input_eda_size=EDA_FT, input_hr_size=HR_FT, \n",
    "#                   emb_eda_size=EMB_EDA_SIZE, emb_hr_size=EMB_HR_SIZE, \n",
    "#                   dropout=DROPOUT, cls_size=CLS_SIZE)\n",
    "# Model = Model.to(device)\n",
    "\n",
    "# params = list(filter(lambda p: p.requires_grad, Model.parameters()))\n",
    "\n",
    "# if OPTIM.lower() == 'adam':\n",
    "#     optimizer = torch.optim.Adam(params, lr=LR)\n",
    "# if OPTIM.lower() == 'sgd':\n",
    "#     optimizer = torch.optim.SGD(params, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539a208b-556c-4b57-a8b1-d5bf79c7d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eda': {'acc': 0.8884758364312267, 'bacc': 0.7497614552246381, 'f1': 0.6629213483146068}, 'hr': {'acc': 0.8591078066914498, 'bacc': 0.6890289705016546, 'f1': 0.5450180072028812}, 'com': {'acc': 0.8903345724907064, 'bacc': 0.7620581846235053, 'f1': 0.6796959826275788}, 'vot': {'acc': 0.8643122676579925, 'bacc': 0.6979089266500194, 'f1': 0.5639187574671446}}\n"
     ]
    }
   ],
   "source": [
    "voting_metric = revoting(subject_id_test=SUBJECT_ID_TEST, dataloader=test_dataloader)\n",
    "print(voting_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2907116-1cbc-4c81-bcc2-39a53d680491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### TRAIN #####\n",
    "# min_loss = 100\n",
    "# count_change_loss = 0\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor = 0.2, patience=3, \n",
    "#                               mode = 'min', verbose=True, min_lr=1e-6)\n",
    "\n",
    "# # Training\n",
    "# for epoch in range(MAX_EPOCH):\n",
    "#     # train epoch\n",
    "#     train_info, loss_train_dict, metric_train_dict = train_epoch(Model, optimizer, train_dataloader, loss_func=cls_func)\n",
    "#     loss_train_info = loss_to_info(loss_train_dict)\n",
    "#     metric_train_info = metric_to_info(metric_train_dict)\n",
    "    \n",
    "#     train_info = train_info + metric_train_info + '\\n'\n",
    "\n",
    "#     metric_val_dict = validate_epoch(Model, validate_dataloader)\n",
    "#     validate_info = metric_to_info(metric_val_dict)\n",
    "#     val_info = f'[CLASSIFY VALIDATE {subject_id_validate} ONLY]\\n'\n",
    "#     val_info += validate_info\n",
    "    \n",
    "#     total_loss_val = 2 - metric_val_dict['com']['f1'] - metric_val_dict['com']['bacc']\n",
    "\n",
    "#     str_info = ''\n",
    "\n",
    "#     if total_loss_val < min_loss - 0.001:\n",
    "#         # save\n",
    "#         torch.save({'epoch': epoch, \n",
    "#                     'model_state_dict': Model.state_dict()},\n",
    "#                     f\"{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/{MODEL_NAME}_{subject_id_test}.pth.tar\")\n",
    "#         min_loss = total_loss_val\n",
    "#         str_info += f'[SAVE]'\n",
    "#         count_change_loss = 0\n",
    "#         print(str_info)\n",
    "#     else:\n",
    "#         count_change_loss += 1\n",
    "#     str_info += f'========== [{epoch}/{MAX_EPOCH-1}] ==========\\n>>>>> TRAIN <<<<<\\n'\n",
    "#     str_info += train_info + '>>>>> VAL <<<<<\\n'\n",
    "#     str_info += val_info \n",
    "\n",
    "#     print(f'========== [VALIDATE {epoch}/{MAX_EPOCH-1}] ==========\\n' + val_info)\n",
    "\n",
    "#     scheduler.step(total_loss_val)\n",
    "\n",
    "#     logging(str_info+'\\n', \n",
    "#             f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Log/Training_{MODEL_NAME}_{subject_id_test}.txt', \n",
    "#             False)\n",
    "\n",
    "#     if count_change_loss >= 5:\n",
    "#         logging('Early Stopping', \n",
    "#                 f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Log/Training_{MODEL_NAME}_{subject_id_test}.txt', \n",
    "#                 True)\n",
    "#         break\n",
    "\n",
    "# #Test\n",
    "# modelCheckpoint = torch.load(f\"{SAVE_MODEL_DIR}/{NAME_DATASET}/Model/{MODEL_NAME}_{subject_id_test}.pth.tar\")\n",
    "# Model.load_state_dict(modelCheckpoint['model_state_dict'])\n",
    "# Model.eval()\n",
    "\n",
    "# print('Run on Test set in final --> LOAD Best Model')\n",
    "# test_metric_dict = validate_epoch(Model, test_dataloader)\n",
    "# test_metric_info = metric_to_info(test_metric_dict)\n",
    "# test_info = f'[CLASSIFY TEST {subject_id_test} ONLY]\\n'\n",
    "# test_info += test_metric_info + '\\n'\n",
    "# logging(test_info, f'{SAVE_MODEL_DIR}/{NAME_DATASET}/Log/Training_{MODEL_NAME}_{subject_id_test}.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206d58a-1714-4aab-b7f7-ffdf02593846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
